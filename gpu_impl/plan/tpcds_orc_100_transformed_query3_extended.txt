STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20210625075520_39da22af-c548-4826-be55-20df3cb00cd3:2
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE), Map 6 (BROADCAST_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)
      DagName: hive_20210625075520_39da22af-c548-4826-be55-20df3cb00cd3:2
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: store_sales
                  Statistics: Num rows: 287997024 Data size: 49714719552 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (ss_sold_date_sk is not null and ss_item_sk is not null) (type: boolean)
                    Statistics: Num rows: 287997024 Data size: 49714719552 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ss_sold_date_sk (type: bigint), ss_item_sk (type: bigint), ss_sales_price (type: double)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 287997024 Data size: 49714719552 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col1 (type: bigint)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col1 (type: bigint)
                        Statistics: Num rows: 287997024 Data size: 49714719552 Basic stats: COMPLETE Column stats: NONE
                        tag: 0
                        value expressions: _col0 (type: bigint), _col2 (type: double)
                        auto parallelism: true
            Execution mode: vectorized
            Path -> Alias:
              hdfs://dbg20:9000/hive-3.1.0/tpcds_orc_100_transformed.db/store_sales [store_sales]
            Path -> Partition:
              hdfs://dbg20:9000/hive-3.1.0/tpcds_orc_100_transformed.db/store_sales 
                Partition
                  base file name: store_sales
                  input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                  output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns ss_sold_date_sk,ss_sold_time_sk,ss_item_sk,ss_customer_sk,ss_cdemo_sk,ss_hdemo_sk,ss_addr_sk,ss_store_sk,ss_promo_sk,ss_ticket_number,ss_quantity,ss_wholesale_cost,ss_list_price,ss_sales_price,ss_ext_discount_amt,ss_ext_sales_price,ss_ext_wholesale_cost,ss_ext_list_price,ss_ext_tax,ss_coupon_amt,ss_net_paid,ss_net_paid_inc_tax,ss_net_profit
                    columns.comments 
                    columns.types bigint:bigint:bigint:bigint:bigint:bigint:bigint:bigint:bigint:bigint:int:double:double:double:double:double:double:double:double:double:double:double:double
                    file.inputformat org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                    location hdfs://dbg20:9000/hive-3.1.0/tpcds_orc_100_transformed.db/store_sales
                    name tpcds_orc_100_transformed.store_sales
                    numFiles 48
                    numRows 287997024
                    orc.compress NONE
                    rawDataSize 49714719552
                    serialization.ddl struct store_sales { i64 ss_sold_date_sk, i64 ss_sold_time_sk, i64 ss_item_sk, i64 ss_customer_sk, i64 ss_cdemo_sk, i64 ss_hdemo_sk, i64 ss_addr_sk, i64 ss_store_sk, i64 ss_promo_sk, i64 ss_ticket_number, i32 ss_quantity, double ss_wholesale_cost, double ss_list_price, double ss_sales_price, double ss_ext_discount_amt, double ss_ext_sales_price, double ss_ext_wholesale_cost, double ss_ext_list_price, double ss_ext_tax, double ss_coupon_amt, double ss_net_paid, double ss_net_paid_inc_tax, double ss_net_profit}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                    totalSize 29705444367
                    transient_lastDdlTime 1621861604
                  serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                
                    input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                    output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                      bucket_count -1
                      bucketing_version 2
                      column.name.delimiter ,
                      columns ss_sold_date_sk,ss_sold_time_sk,ss_item_sk,ss_customer_sk,ss_cdemo_sk,ss_hdemo_sk,ss_addr_sk,ss_store_sk,ss_promo_sk,ss_ticket_number,ss_quantity,ss_wholesale_cost,ss_list_price,ss_sales_price,ss_ext_discount_amt,ss_ext_sales_price,ss_ext_wholesale_cost,ss_ext_list_price,ss_ext_tax,ss_coupon_amt,ss_net_paid,ss_net_paid_inc_tax,ss_net_profit
                      columns.comments 
                      columns.types bigint:bigint:bigint:bigint:bigint:bigint:bigint:bigint:bigint:bigint:int:double:double:double:double:double:double:double:double:double:double:double:double
                      file.inputformat org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      location hdfs://dbg20:9000/hive-3.1.0/tpcds_orc_100_transformed.db/store_sales
                      name tpcds_orc_100_transformed.store_sales
                      numFiles 48
                      numRows 287997024
                      orc.compress NONE
                      rawDataSize 49714719552
                      serialization.ddl struct store_sales { i64 ss_sold_date_sk, i64 ss_sold_time_sk, i64 ss_item_sk, i64 ss_customer_sk, i64 ss_cdemo_sk, i64 ss_hdemo_sk, i64 ss_addr_sk, i64 ss_store_sk, i64 ss_promo_sk, i64 ss_ticket_number, i32 ss_quantity, double ss_wholesale_cost, double ss_list_price, double ss_sales_price, double ss_ext_discount_amt, double ss_ext_sales_price, double ss_ext_wholesale_cost, double ss_ext_list_price, double ss_ext_tax, double ss_coupon_amt, double ss_net_paid, double ss_net_paid_inc_tax, double ss_net_profit}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      totalSize 29705444367
                      transient_lastDdlTime 1621861604
                    serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                    name: tpcds_orc_100_transformed.store_sales
                  name: tpcds_orc_100_transformed.store_sales
            Truncated Path -> Alias:
              /tpcds_orc_100_transformed.db/store_sales [store_sales]
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: item
                  Statistics: Num rows: 204000 Data size: 31805840 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((i_manufact_id = 816) and i_item_sk is not null) (type: boolean)
                    Statistics: Num rows: 102000 Data size: 15902920 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: i_item_sk (type: bigint), i_brand_id (type: int), i_brand (type: bigint)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 102000 Data size: 15902920 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: bigint)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: bigint)
                        Statistics: Num rows: 102000 Data size: 15902920 Basic stats: COMPLETE Column stats: NONE
                        tag: 1
                        value expressions: _col1 (type: int), _col2 (type: bigint)
                        auto parallelism: true
            Execution mode: vectorized
            Path -> Alias:
              hdfs://dbg20:9000/hive-3.1.0/tpcds_orc_100_transformed.db/item [item]
            Path -> Partition:
              hdfs://dbg20:9000/hive-3.1.0/tpcds_orc_100_transformed.db/item 
                Partition
                  base file name: item
                  input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                  output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns i_item_sk,i_item_id,i_rec_start_date,i_rec_end_date,i_item_desc,i_current_price,i_wholesale_cost,i_brand_id,i_brand,i_class_id,i_class,i_category_id,i_category,i_manufact_id,i_manufact,i_size,i_formulation,i_color,i_units,i_container,i_manager_id,i_product_name
                    columns.comments 
                    columns.types bigint:bigint:bigint:bigint:bigint:double:double:int:bigint:int:bigint:int:bigint:int:bigint:bigint:bigint:bigint:bigint:bigint:int:bigint
                    file.inputformat org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                    location hdfs://dbg20:9000/hive-3.1.0/tpcds_orc_100_transformed.db/item
                    name tpcds_orc_100_transformed.item
                    numFiles 1
                    numRows 204000
                    orc.compress NONE
                    rawDataSize 31805840
                    serialization.ddl struct item { i64 i_item_sk, i64 i_item_id, i64 i_rec_start_date, i64 i_rec_end_date, i64 i_item_desc, double i_current_price, double i_wholesale_cost, i32 i_brand_id, i64 i_brand, i32 i_class_id, i64 i_class, i32 i_category_id, i64 i_category, i32 i_manufact_id, i64 i_manufact, i64 i_size, i64 i_formulation, i64 i_color, i64 i_units, i64 i_container, i32 i_manager_id, i64 i_product_name}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                    totalSize 10703781
                    transient_lastDdlTime 1621862432
                  serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                
                    input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                    output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                      bucket_count -1
                      bucketing_version 2
                      column.name.delimiter ,
                      columns i_item_sk,i_item_id,i_rec_start_date,i_rec_end_date,i_item_desc,i_current_price,i_wholesale_cost,i_brand_id,i_brand,i_class_id,i_class,i_category_id,i_category,i_manufact_id,i_manufact,i_size,i_formulation,i_color,i_units,i_container,i_manager_id,i_product_name
                      columns.comments 
                      columns.types bigint:bigint:bigint:bigint:bigint:double:double:int:bigint:int:bigint:int:bigint:int:bigint:bigint:bigint:bigint:bigint:bigint:int:bigint
                      file.inputformat org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      location hdfs://dbg20:9000/hive-3.1.0/tpcds_orc_100_transformed.db/item
                      name tpcds_orc_100_transformed.item
                      numFiles 1
                      numRows 204000
                      orc.compress NONE
                      rawDataSize 31805840
                      serialization.ddl struct item { i64 i_item_sk, i64 i_item_id, i64 i_rec_start_date, i64 i_rec_end_date, i64 i_item_desc, double i_current_price, double i_wholesale_cost, i32 i_brand_id, i64 i_brand, i32 i_class_id, i64 i_class, i32 i_category_id, i64 i_category, i32 i_manufact_id, i64 i_manufact, i64 i_size, i64 i_formulation, i64 i_color, i64 i_units, i64 i_container, i32 i_manager_id, i64 i_product_name}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      totalSize 10703781
                      transient_lastDdlTime 1621862432
                    serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                    name: tpcds_orc_100_transformed.item
                  name: tpcds_orc_100_transformed.item
            Truncated Path -> Alias:
              /tpcds_orc_100_transformed.db/item [item]
        Map 6 
            Map Operator Tree:
                TableScan
                  alias: dt
                  Statistics: Num rows: 73049 Data size: 11980036 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((d_moy = 11) and d_date_sk is not null) (type: boolean)
                    Statistics: Num rows: 36524 Data size: 5989936 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: d_date_sk (type: bigint), d_year (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 36524 Data size: 5989936 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: bigint)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: bigint)
                        Statistics: Num rows: 36524 Data size: 5989936 Basic stats: COMPLETE Column stats: NONE
                        tag: 1
                        value expressions: _col1 (type: int)
                        auto parallelism: true
            Execution mode: vectorized
            Path -> Alias:
              hdfs://dbg20:9000/hive-3.1.0/tpcds_orc_100_transformed.db/date_dim [dt]
            Path -> Partition:
              hdfs://dbg20:9000/hive-3.1.0/tpcds_orc_100_transformed.db/date_dim 
                Partition
                  base file name: date_dim
                  input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                  output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns d_date_sk,d_date_id,d_date,d_month_seq,d_week_seq,d_quarter_seq,d_year,d_dow,d_moy,d_dom,d_qoy,d_fy_year,d_fy_quarter_seq,d_fy_week_seq,d_day_name,d_quarter_name,d_holiday,d_weekend,d_following_holiday,d_first_dom,d_last_dom,d_same_day_ly,d_same_day_lq,d_current_day,d_current_week,d_current_month,d_current_quarter,d_current_year
                    columns.comments 
                    columns.types bigint:bigint:bigint:int:int:int:int:int:int:int:int:int:int:int:bigint:bigint:bigint:bigint:bigint:int:int:int:int:bigint:bigint:bigint:bigint:bigint
                    file.inputformat org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                    location hdfs://dbg20:9000/hive-3.1.0/tpcds_orc_100_transformed.db/date_dim
                    name tpcds_orc_100_transformed.date_dim
                    numFiles 1
                    numRows 73049
                    orc.compress NONE
                    rawDataSize 11980036
                    serialization.ddl struct date_dim { i64 d_date_sk, i64 d_date_id, i64 d_date, i32 d_month_seq, i32 d_week_seq, i32 d_quarter_seq, i32 d_year, i32 d_dow, i32 d_moy, i32 d_dom, i32 d_qoy, i32 d_fy_year, i32 d_fy_quarter_seq, i32 d_fy_week_seq, i64 d_day_name, i64 d_quarter_name, i64 d_holiday, i64 d_weekend, i64 d_following_holiday, i32 d_first_dom, i32 d_last_dom, i32 d_same_day_ly, i32 d_same_day_lq, i64 d_current_day, i64 d_current_week, i64 d_current_month, i64 d_current_quarter, i64 d_current_year}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                    totalSize 607097
                    transient_lastDdlTime 1621862429
                  serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                
                    input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                    output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                      bucket_count -1
                      bucketing_version 2
                      column.name.delimiter ,
                      columns d_date_sk,d_date_id,d_date,d_month_seq,d_week_seq,d_quarter_seq,d_year,d_dow,d_moy,d_dom,d_qoy,d_fy_year,d_fy_quarter_seq,d_fy_week_seq,d_day_name,d_quarter_name,d_holiday,d_weekend,d_following_holiday,d_first_dom,d_last_dom,d_same_day_ly,d_same_day_lq,d_current_day,d_current_week,d_current_month,d_current_quarter,d_current_year
                      columns.comments 
                      columns.types bigint:bigint:bigint:int:int:int:int:int:int:int:int:int:int:int:bigint:bigint:bigint:bigint:bigint:int:int:int:int:bigint:bigint:bigint:bigint:bigint
                      file.inputformat org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      location hdfs://dbg20:9000/hive-3.1.0/tpcds_orc_100_transformed.db/date_dim
                      name tpcds_orc_100_transformed.date_dim
                      numFiles 1
                      numRows 73049
                      orc.compress NONE
                      rawDataSize 11980036
                      serialization.ddl struct date_dim { i64 d_date_sk, i64 d_date_id, i64 d_date, i32 d_month_seq, i32 d_week_seq, i32 d_quarter_seq, i32 d_year, i32 d_dow, i32 d_moy, i32 d_dom, i32 d_qoy, i32 d_fy_year, i32 d_fy_quarter_seq, i32 d_fy_week_seq, i64 d_day_name, i64 d_quarter_name, i64 d_holiday, i64 d_weekend, i64 d_following_holiday, i32 d_first_dom, i32 d_last_dom, i32 d_same_day_ly, i32 d_same_day_lq, i64 d_current_day, i64 d_current_week, i64 d_current_month, i64 d_current_quarter, i64 d_current_year}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      totalSize 607097
                      transient_lastDdlTime 1621862429
                    serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                    name: tpcds_orc_100_transformed.date_dim
                  name: tpcds_orc_100_transformed.date_dim
            Truncated Path -> Alias:
              /tpcds_orc_100_transformed.db/date_dim [dt]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col1 (type: bigint)
                  1 _col0 (type: bigint)
                outputColumnNames: _col0, _col2, _col4, _col5
                Position of Big Table: 0
                Statistics: Num rows: 316796733 Data size: 54686192692 Basic stats: COMPLETE Column stats: NONE
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                  Estimated key counts: Map 6 => 36524
                  keys:
                    0 _col0 (type: bigint)
                    1 _col0 (type: bigint)
                  outputColumnNames: _col2, _col4, _col5, _col8
                  input vertices:
                    1 Map 6
                  Position of Big Table: 0
                  Statistics: Num rows: 348476413 Data size: 60154813265 Basic stats: COMPLETE Column stats: NONE
                  HybridGraceHashJoin: true
                  Group By Operator
                    aggregations: sum(_col2)
                    keys: _col8 (type: int), _col4 (type: int), _col5 (type: bigint)
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Statistics: Num rows: 348476413 Data size: 60154813265 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: int), _col1 (type: int), _col2 (type: bigint)
                      null sort order: aaa
                      sort order: +++
                      Map-reduce partition columns: _col0 (type: int), _col1 (type: int), _col2 (type: bigint)
                      Statistics: Num rows: 348476413 Data size: 60154813265 Basic stats: COMPLETE Column stats: NONE
                      tag: -1
                      value expressions: _col3 (type: double)
                      auto parallelism: true
        Reducer 3 
            Execution mode: vectorized
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: int), KEY._col1 (type: int), KEY._col2 (type: bigint)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 174238206 Data size: 30077406546 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int), _col3 (type: double), _col1 (type: int)
                  null sort order: aza
                  sort order: +-+
                  Statistics: Num rows: 174238206 Data size: 30077406546 Basic stats: COMPLETE Column stats: NONE
                  tag: -1
                  TopN: 100
                  TopN Hash Memory Usage: 0.1
                  value expressions: _col2 (type: bigint)
                  auto parallelism: false
        Reducer 4 
            Execution mode: vectorized
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey2 (type: int), VALUE._col0 (type: bigint), KEY.reducesinkkey1 (type: double)
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 174238206 Data size: 30077406546 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 100
                  Statistics: Num rows: 100 Data size: 17200 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://dbg20:9000/tmp/hive/hive/e539d0b3-7ef9-4fc8-89c7-11580dba6103/hive_2021-06-25_07-55-20_158_1280148860614284091-1/-mr-10001/.hive-staging_hive_2021-06-25_07-55-20_158_1280148860614284091-1/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 100 Data size: 17200 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://dbg20:9000/tmp/hive/hive/e539d0b3-7ef9-4fc8-89c7-11580dba6103/hive_2021-06-25_07-55-20_158_1280148860614284091-1/-mr-10001/.hive-staging_hive_2021-06-25_07-55-20_158_1280148860614284091-1/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1,_col2,_col3
                          columns.types int:int:bigint:double
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 100
      Processor Tree:
        ListSink


